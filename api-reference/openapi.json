{
  "openapi": "3.0.0",
  "info": {
    "title": "Aerspan API",
    "description": "The Aerspan REST API",
    "version": "1.0.0"
  },
  "servers": [
    {
      "url": "https://api.aerspan.com/v1"
    }
  ],
  "security": [
    {
      "bearerAuth": []
    }
  ],
  "paths": {
    "/chat/completions": {
      "post": {
        "tags": ["Chat Completions"],
        "summary": "Chat Completions",
        "description": "Creates a model response for the given chat conversation.",
        "operationId": "chat-completions",
        "requestBody": {
          "content": {
            "application/json": {
              "schema": {
                "oneOf": [
                  {
                    "$ref": "#/components/schemas/ChatCompletionRequest"
                  },
                  {
                    "$ref": "#/components/schemas/ChatCompletionVLMRequest"
                  }
                ]
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "200",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ChatCompletionResponse"
                }
              },
              "text/event-stream": {
                "schema": {
                  "$ref": "#/components/schemas/ChatCompletionStream"
                }
              }
            }
          },
          "400": {
            "description": "BadRequest",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorData"
                }
              }
            }
          },
          "401": {
            "description": "Unauthorized",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorData"
                }
              }
            }
          },
          "404": {
            "description": "NotFound",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorData"
                }
              }
            }
          },
          "429": {
            "description": "RateLimit",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorData"
                }
              }
            }
          },
          "503": {
            "description": "Overloaded",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorData"
                }
              }
            }
          },
          "504": {
            "description": "Timeout",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorData"
                }
              }
            }
          }
        },
        "deprecated": false
      }
    },
    "/completions": {
      "post": {
        "tags": ["Completion"],
        "summary": "Create completion",
        "description": "Query a language, code, or image model.",
        "operationId": "completions",
        "requestBody": {
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/CompletionRequest"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "200",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/CompletionResponse"
                }
              },
              "text/event-stream": {
                "schema": {
                  "$ref": "#/components/schemas/CompletionStream"
                }
              }
            }
          },
          "400": {
            "description": "BadRequest",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorData"
                }
              }
            }
          },
          "401": {
            "description": "Unauthorized",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorData"
                }
              }
            }
          },
          "404": {
            "description": "NotFound",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorData"
                }
              }
            }
          },
          "429": {
            "description": "RateLimit",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorData"
                }
              }
            }
          },
          "503": {
            "description": "Overloaded",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorData"
                }
              }
            }
          },
          "504": {
            "description": "Timeout",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorData"
                }
              }
            }
          }
        },
        "deprecated": false
      }
    }
  },
  "components": {
    "schemas": {
      "ChatCompletionRequest": {
        "title": "LLM",
        "type": "object",
        "required": ["model", "messages"],
        "properties": {
          "model": {
            "type": "string",
            "description": "Corresponding Model Name. To better enhance service quality, we will make periodic changes to the models provided by this service, including but not limited to model on/offlining and adjustments to model service capabilities. We will notify you of such changes through appropriate means such as announcements or message pushes where feasible.",
            "example": "minimax/minimax-m2.1",
            "enum": [
              "minimax-m2.1",
              "deepseek-v3-0324",
              "deepseek-v3",
              "deepseek-v3.1",
              "deepseek-v3.2",
              "deepseek-r1",
              "deepseek-r1-0528",
              "glm-4.6",
              "glm-4.6v",
              "glm-4.7",
              "qwen3-coder-480b-a35b-instruct",
              "qwen3-235b-a22b-instruct-2507",
              "gpt-oss-120b",
              "gpt-oss-20b"
            ]
          },
          "messages": {
            "type": "array",
            "description": "A list of messages comprising the conversation so far.",
            "items": {
              "type": "object",
              "properties": {
                "role": {
                  "type": "string",
                  "description": "The role of the messages author. Choice between: system, user, or assistant.",
                  "example": "user",
                  "default": "user",
                  "enum": ["user", "assistant", "system"]
                },
                "content": {
                  "oneOf": [
                    {
                      "type": "string",
                      "description": "The contents of the message.",
                      "example": "What opportunities and challenges will the Chinese large model industry face in 2025?",
                      "default": "What opportunities and challenges will the Chinese large model industry face in 2025?"
                    }
                  ]
                }
              },
              "required": ["role", "content"]
            },
            "minItems": 1,
            "maxItems": 10
          },
          "stream": {
            "type": "boolean",
            "description": "If set, tokens are returned as Server-Sent Events as they are made available. Stream terminates with `data: [DONE]`",
            "example": false
          },
          "max_tokens": {
            "type": "integer",
            "description": "The maximum number of tokens to generate. Ensure that input tokens + max_tokens do not exceed the model’s context window. As some services are still being updated, avoid setting max_tokens to the window’s upper bound; reserve ~10k tokens as buffer for input and system overhead. See Models(https://app.aerspan.com/models) for details.\n",
            "example": 4096
          },
          "enable_thinking": {
            "type": "boolean",
            "description": "Switches between thinking and non-thinking modes. Default is True. This field supports the following models:\n\n    - Qwen/Qwen3-8B\n    - Qwen/Qwen3-14B\n    - Qwen/Qwen3-32B\n    - wen/Qwen3-30B-A3B\n    - Qwen/Qwen3-235B-A22B\n    - tencent/Hunyuan-A13B-Instruct\n    - zai-org/GLM-4.6V\n    - zai-org/GLM-4.5V\n    - deepseek-ai/DeepSeek-V3.1\n    - deepseek-ai/DeepSeek-V3.1-Terminus\n    - deepseek-ai/DeepSeek-V3.2-Exp\n    - deepseek-ai/DeepSeek-V3.2\n\nIf you want to use the function call feature for deepseek-ai/DeepSeek-V3.1, you need to set enable_thinking to false.\n",
            "example": false
          },
          "thinking_budget": {
            "type": "integer",
            "description": "Maximum number of tokens for chain-of-thought output. This field applies to all Reasoning models.",
            "example": 4096,
            "default": 4096,
            "minimum": 128,
            "maximum": 32768
          },
          "min_p": {
            "type": "number",
            "description": "Dynamic filtering threshold that adapts based on token probabilities.This field only applies to Qwen3.",
            "format": "float",
            "example": 0.05,
            "minimum": 0,
            "maximum": 1
          },
          "stop": {
            "description": "Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.\n",
            "nullable": true,
            "oneOf": [
              {
                "type": "string",
                "example": null,
                "nullable": true
              },
              {
                "type": "array",
                "minItems": 1,
                "maxItems": 4,
                "items": {
                  "type": "string",
                  "example": "null"
                }
              }
            ]
          },
          "temperature": {
            "type": "number",
            "description": "Determines the degree of randomness in the response.",
            "format": "float",
            "example": 0.7
          },
          "top_p": {
            "type": "number",
            "description": "The `top_p` (nucleus) parameter is used to dynamically adjust the number of choices for each predicted token based on the cumulative probabilities.",
            "format": "float",
            "example": 0.7,
            "default": 0.7
          },
          "top_k": {
            "type": "number",
            "format": "float",
            "example": 50
          },
          "frequency_penalty": {
            "type": "number",
            "format": "float",
            "example": 0.5
          },
          "n": {
            "type": "integer",
            "description": "Number of generations to return",
            "example": 1
          },
          "response_format": {
            "type": "object",
            "description": "An object specifying the format that the model must output.",
            "properties": {
              "type": {
                "type": "string",
                "description": "The type of the response format.",
                "example": "text"
              }
            }
          },
          "tools": {
            "type": "array",
            "description": "A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.\n",
            "items": {
              "$ref": "#/components/schemas/ChatCompletionTool"
            }
          }
        }
      },
      "ChatCompletionVLMRequest": {
        "title": "VLM",
        "type": "object",
        "required": ["model", "messages"],
        "properties": {
          "model": {
            "type": "string",
            "description": "Corresponding Model Name. To better enhance service quality, we will make periodic changes to the models provided by this service, including but not limited to model on/offlining and adjustments to model service capabilities. We will notify you of such changes through appropriate means such as announcements or message pushes where feasible.",
            "example": "glm-4.6v",
            "default": "glm-4.6v",
            "enum": [
              "minimax-m2.1",
              "deepseek-v3-0324",
              "deepseek-v3",
              "deepseek-v3.1",
              "deepseek-v3.2",
              "deepseek-r1",
              "deepseek-r1-0528",
              "glm-4.6",
              "glm-4.6v",
              "glm-4.7",
              "qwen3-coder-480b-a35b-instruct",
              "qwen3-235b-a22b-instruct-2507",
              "gpt-oss-120b",
              "gpt-oss-20b"
            ]
          },
          "messages": {
            "type": "array",
            "description": "A list of messages comprising the conversation so far.",
            "items": {
              "type": "object",
              "properties": {
                "role": {
                  "type": "string",
                  "description": "The role of the messages author. Choice between: system, user, or assistant.",
                  "example": "user",
                  "default": "user",
                  "enum": ["user", "assistant", "system"]
                },
                "content": {
                  "oneOf": [
                    {
                      "type": "array",
                      "description": "An array of content parts with a defined type, each can be of type `text` or `image_url` when passing in images. You can pass multiple images by adding multiple `image_url` content parts. The Qwen3-Omni series supports `video_url` and `audio_url`, enabling the recognition of video and audio content. The Qwen3-VL model also supports `video_url`, allowing it to recognize video content. Recommend videos and audio within 30 seconds.",
                      "items": {
                        "$ref": "#/components/schemas/ChatCompletionRequestUserMessageContentPart"
                      },
                      "minItems": 1
                    }
                  ]
                }
              },
              "required": ["role", "content"]
            },
            "minItems": 1,
            "maxItems": 10
          },
          "stream": {
            "type": "boolean",
            "description": "If set, tokens are returned as Server-Sent Events as they are made available. Stream terminates with `data: [DONE]`",
            "example": false,
            "default": false
          },
          "max_tokens": {
            "type": "integer",
            "description": "The maximum number of tokens to generate. Ensure that input tokens + max_tokens do not exceed the model’s context window. As some services are still being updated, avoid setting max_tokens to the window’s upper bound; reserve ~10k tokens as buffer for input and system overhead. See Models(https://app.aerspan.com/models) for details.\n"
          },
          "stop": {
            "description": "Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.\n",
            "default": [],
            "nullable": true,
            "oneOf": [
              {
                "type": "array",
                "minItems": 1,
                "maxItems": 4,
                "items": {
                  "type": "string",
                  "example": "null"
                }
              },
              {
                "type": "string",
                "default": "<|endoftext|>",
                "example": "\n",
                "nullable": true
              },
              {
                "type": "string",
                "default": "<|endoftext|>",
                "example": "",
                "nullable": true
              }
            ]
          },
          "temperature": {
            "type": "number",
            "description": "Determines the degree of randomness in the response.",
            "format": "float",
            "example": 0.7,
            "default": 0.7
          },
          "top_p": {
            "type": "number",
            "description": "The `top_p` (nucleus) parameter is used to dynamically adjust the number of choices for each predicted token based on the cumulative probabilities.",
            "format": "float",
            "example": 0.7,
            "default": 0.7
          },
          "top_k": {
            "type": "number",
            "format": "float",
            "example": 50,
            "default": 50
          },
          "frequency_penalty": {
            "type": "number",
            "format": "float",
            "example": 0.5,
            "default": 0.5
          },
          "n": {
            "type": "integer",
            "description": "Number of generations to return",
            "example": 1,
            "default": 1
          },
          "response_format": {
            "type": "object",
            "description": "An object specifying the format that the model must output.",
            "properties": {
              "type": {
                "type": "string",
                "description": "The type of the response format.",
                "example": "text"
              }
            }
          }
        }
      },
      "ChatCompletionResponse": {
        "type": "object",
        "properties": {
          "id": {
            "type": "string"
          },
          "choices": {
            "$ref": "#/components/schemas/ChatCompletionChoicesData"
          },
          "usage": {
            "$ref": "#/components/schemas/UsageData"
          },
          "created": {
            "type": "integer"
          },
          "model": {
            "type": "string"
          },
          "object": {
            "type": "string",
            "enum": ["chat.completion"]
          }
        }
      },
      "ChatCompletionStream": {
        "type": "object",
        "properties": {
          "id": {
            "type": "string"
          },
          "choices": {
            "$ref": "#/components/schemas/ChatCompletionChoicesData"
          },
          "created": {
            "type": "integer"
          },
          "model": {
            "type": "string"
          },
          "object": {
            "type": "string",
            "enum": ["chat.completion.chunk"]
          }
        }
      },
      "CompletionRequest": {
        "type": "object",
        "required": ["model", "prompt"],
        "properties": {
          "prompt": {
            "type": "string",
            "description": "A string providing context for the model to complete.",
            "example": "<s>[INST] What is the capital of Germany? [/INST]"
          },
          "model": {
            "type": "string",
            "description": "The name of the model to query [See all of Aerspan's chat models](https://app.aerspan.com/models)\n",
            "example": "minimax-m2.1",
            "default": "minimax-m2.1",
            "enum": [
              "minimax-m2.1",
              "deepseek-v3-0324",
              "deepseek-v3",
              "deepseek-v3.1",
              "deepseek-v3.2",
              "deepseek-r1",
              "deepseek-r1-0528",
              "glm-4.6",
              "glm-4.6v",
              "glm-4.7",
              "qwen3-coder-480b-a35b-instruct",
              "qwen3-235b-a22b-instruct-2507",
              "gpt-oss-120b",
              "gpt-oss-20b"
            ]
          },
          "max_tokens": {
            "type": "integer",
            "description": "The maximum number of tokens to generate."
          },
          "stop": {
            "type": "array",
            "description": "A list of string sequences that will truncate (stop) inference text output. For example, \"</s>\" will stop generation as soon as the model generates the given token.",
            "items": {
              "type": "string"
            }
          },
          "temperature": {
            "type": "number",
            "description": "A decimal number from 0-1 that determines the degree of randomness in the response. A temperature less than 1 favors more correctness and is appropriate for question answering or summarization. A value closer to 1 introduces more randomness in the output.",
            "format": "float"
          },
          "top_p": {
            "type": "number",
            "description": "A percentage (also called the nucleus parameter) that's used to dynamically adjust the number of choices for each predicted token based on the cumulative probabilities. It specifies a probability threshold below which all less likely tokens are filtered out. This technique helps maintain diversity and generate more fluent and natural-sounding text.",
            "format": "float"
          },
          "top_k": {
            "type": "integer",
            "description": "An integer that's used to limit the number of choices for the next predicted word or token. It specifies the maximum number of tokens to consider at each step, based on their probability of occurrence. This technique helps to speed up the generation process and can improve the quality of the generated text by focusing on the most likely options.",
            "format": "int32"
          },
          "repetition_penalty": {
            "type": "number",
            "description": "A number that controls the diversity of generated text by reducing the likelihood of repeated sequences. Higher values decrease repetition.",
            "format": "float"
          },
          "stream": {
            "type": "boolean",
            "description": "If true, stream tokens as Server-Sent Events as the model generates them instead of waiting for the full model response. The stream terminates with `data: [DONE]`. If false, return a single JSON object containing the results."
          },
          "n": {
            "type": "integer",
            "description": "The number of completions to generate for each prompt.",
            "minimum": 1,
            "maximum": 128
          },
          "presence_penalty": {
            "type": "number",
            "description": "A number between -2.0 and 2.0 where a positive value increases the likelihood of a model talking about new topics.",
            "format": "float"
          },
          "frequency_penalty": {
            "type": "number",
            "description": "A number between -2.0 and 2.0 where a positive value decreases the likelihood of repeating tokens that have already been mentioned.",
            "format": "float"
          },
          "logit_bias": {
            "type": "object",
            "additionalProperties": {
              "type": "number",
              "format": "float"
            },
            "description": "Adjusts the likelihood of specific tokens appearing in the generated output.",
            "example": {
              "105": 21.4,
              "1024": -10.5
            }
          },
          "seed": {
            "type": "integer",
            "description": "If specified, the system will make its best effort to perform deterministic sampling, so repeated requests with the same seed and parameters should return the same results. Determinism is not guaranteed to be implemented; the system_fingerprint response parameter should be referenced to monitor backend changes.",
            "example": 42
          }
        }
      },
      "CompletionResponse": {
        "type": "object",
        "properties": {
          "id": {
            "type": "string"
          },
          "choices": {
            "$ref": "#/components/schemas/CompletionChoicesData"
          },
          "prompt": {
            "$ref": "#/components/schemas/PromptPart"
          },
          "usage": {
            "$ref": "#/components/schemas/UsageData"
          },
          "created": {
            "type": "integer"
          },
          "model": {
            "type": "string"
          },
          "object": {
            "type": "string",
            "enum": ["text_completion"]
          }
        },
        "required": ["id", "choices", "usage", "created", "model", "object"]
      },
      "CompletionStream": {
        "oneOf": [
          {
            "$ref": "#/components/schemas/CompletionEvent"
          }
        ]
      },
      "ErrorData": {
        "type": "object",
        "required": ["error"],
        "properties": {
          "error": {
            "type": "object",
            "properties": {
              "message": {
                "type": "string",
                "nullable": false
              },
              "type": {
                "type": "string",
                "nullable": false
              },
              "param": {
                "type": "string",
                "nullable": true,
                "default": null
              },
              "code": {
                "type": "string",
                "nullable": true,
                "default": null
              }
            },
            "required": ["type", "message", "param", "code"]
          }
        }
      },
      "ChatCompletionTool": {
        "type": "object",
        "properties": {
          "type": {
            "type": "string",
            "enum": ["function"],
            "description": "The type of the tool. Currently, only `function` is supported."
          },
          "function": {
            "$ref": "#/components/schemas/FunctionObject"
          }
        },
        "required": ["type", "function"]
      },
      "ChatCompletionRequestUserMessageContentPart": {
        "oneOf": [
          {
            "$ref": "#/components/schemas/ChatCompletionRequestMessageContentPartImage"
          },
          {
            "$ref": "#/components/schemas/ChatCompletionRequestMessageContentPartText"
          }
        ],
        "x-oaiExpandable": true
      },
      "ChatCompletionChoicesData": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "message": {
              "type": "object",
              "properties": {
                "role": {
                  "type": "string",
                  "example": "assistant"
                },
                "content": {
                  "type": "string"
                },
                "reasoning_content": {
                  "description": "Only the deepseek-R1 series and Qwen/QwQ-32B models support reasoning_content. This part returns the reasoning content, which is at the same level as the content. In each round of the conversation, the model outputs the reasoning chain content (reasoning_content) and the final answer (content). In the next round of the conversation, the reasoning chain content from previous rounds will not be appended to the context.",
                  "type": "string"
                },
                "tool_calls": {
                  "type": "array",
                  "description": "The tool calls generated by the model, such as function calls.",
                  "items": {
                    "$ref": "#/components/schemas/ChatCompletionMessageToolCall"
                  }
                }
              }
            },
            "finish_reason": {
              "$ref": "#/components/schemas/FinishReason"
            }
          }
        }
      },
      "CompletionChoicesData": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "text": {
              "type": "string"
            },
            "finish_reason": {
              "$ref": "#/components/schemas/FinishReason"
            },
            "logprobs": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/LogprobsPart"
                },
                {
                  "nullable": true
                }
              ]
            }
          }
        }
      },
      "UsageData": {
        "type": "object",
        "properties": {
          "prompt_tokens": {
            "type": "integer"
          },
          "completion_tokens": {
            "type": "integer"
          },
          "total_tokens": {
            "type": "integer"
          }
        }
      },
      "FunctionObject": {
        "type": "object",
        "properties": {
          "description": {
            "type": "string",
            "description": "A description of what the function does, used by the model to choose when and how to call the function."
          },
          "name": {
            "type": "string",
            "description": "The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64."
          },
          "parameters": {
            "$ref": "#/components/schemas/FunctionParameters"
          },
          "strict": {
            "type": "boolean",
            "nullable": true,
            "default": false,
            "description": "Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the `parameters` field. Only a subset of JSON Schema is supported when `strict` is `true`. Learn more about Structured Outputs in the function calling guide."
          }
        },
        "required": ["name"]
      },
      "ChatCompletionRequestMessageContentPartImage": {
        "type": "object",
        "title": "Image content part",
        "properties": {
          "type": {
            "type": "string",
            "enum": ["image_url"],
            "description": "The type of the content part.",
            "default": "image_url"
          },
          "image_url": {
            "type": "object",
            "properties": {
              "url": {
                "type": "string",
                "description": "Either a URL of the image or the base64 encoded image data.",
                "default": "https://sf-maas.s3.us-east-1.amazonaws.com/images/recu6XreBFQ0st.png",
                "example": "https://sf-maas.s3.us-east-1.amazonaws.com/images/recu6XreBFQ0st.png"
              },
              "detail": {
                "type": "string",
                "description": "Specifies the detail level of the image.",
                "enum": ["auto", "low", "high"],
                "default": "auto"
              }
            },
            "required": ["url"]
          }
        },
        "required": ["type", "image_url"]
      },
      "ChatCompletionRequestMessageContentPartText": {
        "type": "object",
        "title": "Text content part",
        "properties": {
          "type": {
            "type": "string",
            "enum": ["text"],
            "description": "The type of the content part.",
            "default": "text"
          },
          "text": {
            "type": "string",
            "description": "The text content.",
            "default": "Describe this picture."
          }
        },
        "required": ["type", "text"]
      },
      "ChatCompletionMessageToolCall": {
        "type": "object",
        "properties": {
          "id": {
            "type": "string",
            "description": "The ID of the tool call."
          },
          "type": {
            "type": "string",
            "enum": ["function"],
            "description": "The type of the tool. Currently, only `function` is supported."
          },
          "function": {
            "type": "object",
            "description": "The function that the model called.",
            "properties": {
              "name": {
                "type": "string",
                "description": "The name of the function to call."
              },
              "arguments": {
                "type": "string",
                "description": "The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function."
              }
            },
            "required": ["name", "arguments"]
          }
        },
        "required": ["id", "type", "function"]
      },
      "FinishReason": {
        "type": "string",
        "enum": ["stop", "eos", "length", "tool_calls"]
      },
      "FunctionParameters": {
        "type": "object",
        "description": "The parameters the functions accepts, described as a JSON Schema object. See the guide for examples, and the JSON Schema reference for documentation about the format.\nOmitting `parameters` defines a function with an empty parameter list.",
        "additionalProperties": true
      },
      "PromptPart": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "text": {
              "type": "string",
              "example": "<s>[INST] What is the capital of France? [/INST]",
              "default": "<s>[INST] What is the capital of France? [/INST]"
            },
            "logprobs": {
              "$ref": "#/components/schemas/LogprobsPart"
            }
          }
        }
      },
      "CompletionEvent": {
        "type": "object",
        "required": ["data"],
        "properties": {
          "data": {
            "$ref": "#/components/schemas/CompletionChunk"
          }
        }
      },
      "LogprobsPart": {
        "type": "object",
        "properties": {
          "tokens": {
            "type": "array",
            "items": {
              "type": "string"
            },
            "description": "List of token strings"
          },
          "token_logprobs": {
            "type": "array",
            "items": {
              "type": "number",
              "format": "float"
            },
            "description": "List of token log probabilities"
          }
        }
      },
      "CompletionChunk": {
        "type": "object",
        "required": ["id", "token", "choices", "usage", "finish_reason"],
        "properties": {
          "id": {
            "type": "string"
          },
          "token": {
            "$ref": "#/components/schemas/CompletionToken"
          },
          "choices": {
            "title": "CompletionChoices",
            "type": "array",
            "items": {
              "$ref": "#/components/schemas/CompletionChoice"
            }
          },
          "tool_calls": {
            "type": "array",
            "items": {
              "$ref": "#/components/schemas/ChatCompletionMessageToolCallChunk"
            }
          },
          "usage": {
            "allOf": [
              {
                "$ref": "#/components/schemas/UsageData"
              },
              {
                "nullable": true
              }
            ]
          },
          "finish_reason": {
            "allOf": [
              {
                "$ref": "#/components/schemas/FinishReason"
              },
              {
                "nullable": true
              }
            ]
          }
        }
      },
      "CompletionToken": {
        "type": "object",
        "required": ["id", "text", "logprob", "special"],
        "properties": {
          "id": {
            "type": "integer"
          },
          "text": {
            "type": "string"
          },
          "logprob": {
            "type": "number",
            "format": "float"
          },
          "special": {
            "type": "boolean"
          }
        }
      },
      "CompletionChoice": {
        "type": "object",
        "required": ["index"],
        "properties": {
          "text": {
            "type": "string"
          }
        }
      },
      "ChatCompletionMessageToolCallChunk": {
        "type": "object",
        "properties": {
          "index": {
            "type": "integer"
          },
          "id": {
            "type": "string",
            "description": "The ID of the tool call."
          },
          "type": {
            "type": "string",
            "enum": ["function"],
            "description": "The type of the tool. Currently, only `function` is supported."
          },
          "function": {
            "type": "object",
            "properties": {
              "name": {
                "type": "string",
                "description": "The name of the function to call."
              },
              "arguments": {
                "type": "string",
                "description": "The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function."
              }
            }
          }
        },
        "required": ["index"]
      }
    },
    "securitySchemes": {
      "bearerAuth": {
        "type": "http",
        "scheme": "bearer",
        "bearerFormat": "your api key",
        "description": "Use the following format for authentication: Bearer [<your api key>](https://app.aerspan.com/api-keys)"
      }
    }
  }
}
